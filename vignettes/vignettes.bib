@inproceedings{guptaChasingCarbonElusive2021,
  title = {Chasing {{Carbon}}: {{The Elusive Environmental Footprint}} of {{Computing}}},
  shorttitle = {Chasing {{Carbon}}},
  booktitle = {2021 {{IEEE International Symposium}} on {{High-Performance Computer Architecture}} ({{HPCA}})},
  author = {Gupta, Udit and Kim, Young Geun and Lee, Sylvia and Tse, Jordan and Lee, Hsien-Hsin S. and Wei, Gu-Yeon and Brooks, David and Wu, Carole-Jean},
  year = {2021},
  month = feb,
  pages = {854--867},
  issn = {2378-203X},
  doi = {10.1109/HPCA51647.2021.00076},
  urldate = {2024-09-15},
  abstract = {Given recent algorithm, software, and hardware innovation, computing has enabled a plethora of new applications. As computing becomes increasingly ubiquitous, however, so does its environmental impact. This paper brings the issue to the attention of computer-systems researchers. Our analysis, built on industry-reported characterization, quantifies the environmental effects of computing in terms of carbon emissions. Broadly, carbon emissions have two sources: operational energy consumption, and hardware manufacturing and infrastructure. Although carbon emissions from the former are decreasing thanks to algorithmic, software, and hardware innovations that boost performance and power efficiency, the overall carbon footprint of computer systems continues to grow. This work quantifies the carbon output of computer systems to show that most emissions related to modern mobile and data-center equipment come from hardware manufacturing and infrastructure. We therefore outline future directions for minimizing the environmental impact of computing systems.},
  keywords = {Carbon dioxide,carbon footprint,Computer architecture,Data center,energy,Energy consumption,Hardware,mobile,Software,Software algorithms,Technological innovation},
  file = {C\:\\Users\\vanlissa\\Zotero\\storage\\J9TEK2BV\\Gupta et al. - 2021 - Chasing Carbon The Elusive Environmental Footprin.pdf;C\:\\Users\\vanlissa\\Zotero\\storage\\DIPFQPS9\\9407142.html}
}

@article{aalbersbergMakingScienceTransparent2018,
  title = {Making {{Science Transparent By Default}}; {{Introducing}} the {{TOP Statement}}},
  author = {Aalbersberg, IJsbrand Jan and Appleyard, Tom and Brookhart, Sarah and Carpenter, Todd and Clarke, Michael and Curry, Stephen and Dahl, Josh and DeHaven, Alexander Carl and Eich, Eric and Franko, Maryrose and Freedman, Len and Graf, Chris and Grant, Sean and Hanson, Brooks and Joseph, Heather and Kiermer, Veronique and Kramer, Bianca and Kraut, Alan and Karn, Roshan Kumar and Lee, Carole and MacFarlane, Aki and Martone, Maryann and Mayo-Wilson, Evan and McNutt, Marcia and McPhail, Meredith and Mellor, David Thomas and Moher, David and Mudditt, Alison and Nosek, Brian A. and Orland, Belinda and Parker, Timothy H. and Parsons, Mark and Patterson, Mark and Santos, Solange and Shore, Carolyn and Simons, Daniel J. and Spellman, Bobbie and Spies, Jeffrey Robert and Spitzer, Matthew and Stodden, Victoria and Swaminathan, Sowmya and Sweet, Deborah and Tsui, Anne and Vazire, Simine},
  date = {2018-02-15},
  doi = {10.31219/osf.io/sm78t},
  url = {https://osf.io/sm78t},
  urldate = {2020-01-08},
  abstract = {In order to increase the replicability of scientific work, the scientific community has called for practices designed to increase the transparency of research (McNutt, 2014; Nosek et al., 2015). The validity of a scientific claim depends not on the reputation of those making the claim, the venue in which the claim is made, or the novelty of the result, but rather on the empirical evidence provided by the underlying data and methods. Proper evaluation of  the merits of scientific findings requires availability of the methods, materials, and data and the reasoned argument that serve as the basis for the published conclusions (Claerbout and Karrenbach 1992; Donoho et al 2009; Stodden et al 2013; Borwein et al 2013; Munaf√≤ et al, 2017). Wide and growing support for these principles (see, for example, signatories to Declaration on Research Assessment, DORA, https://sfdora.org/, and the Transparency and Openness Promotion Guidelines https://cos.io/our-services/top-guidelines/) must be coupled with guidelines to increase open sharing of data and research materials, use of reporting guidelines, preregistration, and replication. We propose that, going forward, authors of all scientific articles disclose the availability and location of all research items, including data, materials, and code, related to their published articles in what we will refer to as a TOP Statement.}
}

@article{vanlissaWORCSWorkflowOpen2021,
  title = {{{WORCS}}: {{A}} Workflow for Open Reproducible Code in Science},
  author = {Van Lissa, Caspar J. and Brandmaier, Andreas M. and Brinkman, Loek and Lamprecht, Anna-Lena and Peikert, Aaron and Struiksma, Marijn E. and Vreede, Barbara M.I.},
  year = {2021},
  journal = {Data Science},
  volume = {4},
  number = {1},
  pages = {29--49},
  publisher = {{IOS Press}},
  issn = {2451-8492},
  doi = {10.3233/DS-210031},
  abstract = {Adopting open science principles can be challenging, requiring conceptual education and training in the use of new tools. This paper introduces the Workflow for Open Reproducible Code in Science (WORCS): A step-by-step procedure that researchers can follow to make a research project open and reproducible. This workflow intends to lower the threshold for adoption of open science principles. It is based on established best practices, and can be used either in parallel to, or in absence of, top-down requirements by journals, institutions, and funding bodies. To facilitate widespread adoption, the WORCS principles have been implemented in the R package worcs , which offers an RStudio project template and utility functions for specific workflow steps. This paper introduces the conceptual workflow, discusses how it meets different standards for open science, and addresses the functionality provided by the R implementation, worcs . This paper is primarily targeted towards scholars conducting research projects in R, conducting research that involves academic prose, analysis code, and tabular data. However, the workflow is flexible enough to accommodate other scenarios, and offers a starting point for customized solutions. The source code for the R package and manuscript, and a list of examplesof WORCS projects , are available at https://github.com/cjvanlissa/worcs .},
  keywords = {dynamic document generation,Open science,r,reproducibility,version control}
}



